{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-03-19T03:09:59.392908Z","iopub.execute_input":"2023-03-19T03:09:59.393613Z","iopub.status.idle":"2023-03-19T03:10:12.227052Z","shell.execute_reply.started":"2023-03-19T03:09:59.393572Z","shell.execute_reply":"2023-03-19T03:10:12.225824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nimport pandas as pd\nimport numpy as np\nimport torch\nimport random\nimport torch\n\nrandom.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:10:12.230987Z","iopub.execute_input":"2023-03-19T03:10:12.231379Z","iopub.status.idle":"2023-03-19T03:10:24.996532Z","shell.execute_reply.started":"2023-03-19T03:10:12.231344Z","shell.execute_reply":"2023-03-19T03:10:24.995419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:10:24.998127Z","iopub.execute_input":"2023-03-19T03:10:24.998943Z","iopub.status.idle":"2023-03-19T03:10:25.263187Z","shell.execute_reply.started":"2023-03-19T03:10:24.998899Z","shell.execute_reply":"2023-03-19T03:10:25.262165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experimental Data Analysis","metadata":{}},{"cell_type":"code","source":"data.groupby(by = \"discourse_type\").count()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:10:25.267941Z","iopub.execute_input":"2023-03-19T03:10:25.268256Z","iopub.status.idle":"2023-03-19T03:10:25.306732Z","shell.execute_reply.started":"2023-03-19T03:10:25.268227Z","shell.execute_reply":"2023-03-19T03:10:25.305820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Obtaining the topics\n\nThis part is responsible for providing some ground truth as to which essay belongs to which topic, to simplify the semantic search retrieval problem. ","metadata":{}},{"cell_type":"code","source":"!pip install bertopic[use]","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:10:25.308221Z","iopub.execute_input":"2023-03-19T03:10:25.308565Z","iopub.status.idle":"2023-03-19T03:11:59.394643Z","shell.execute_reply.started":"2023-03-19T03:10:25.308529Z","shell.execute_reply":"2023-03-19T03:11:59.393423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essay_collection = data.groupby(\"essay_id\").agg(\" \".join)\nprint(essay_collection)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:11:59.396980Z","iopub.execute_input":"2023-03-19T03:11:59.397629Z","iopub.status.idle":"2023-03-19T03:11:59.556160Z","shell.execute_reply.started":"2023-03-19T03:11:59.397581Z","shell.execute_reply":"2023-03-19T03:11:59.554969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bertopic import BERTopic\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom umap import UMAP\nfrom sklearn.cluster import KMeans\n\ncluster_model = KMeans(n_clusters=15)\n\numap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\nvectorizer_model = CountVectorizer(stop_words=\"english\")\ntopic_model = BERTopic(vectorizer_model=vectorizer_model, umap_model = umap_model, hdbscan_model=cluster_model)\ntopics, probs = topic_model.fit_transform(essay_collection['discourse_text'])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:11:59.557835Z","iopub.execute_input":"2023-03-19T03:11:59.558255Z","iopub.status.idle":"2023-03-19T03:13:24.265512Z","shell.execute_reply.started":"2023-03-19T03:11:59.558216Z","shell.execute_reply":"2023-03-19T03:13:24.264010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_model.get_topics()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.270631Z","iopub.execute_input":"2023-03-19T03:13:24.271465Z","iopub.status.idle":"2023-03-19T03:13:24.296847Z","shell.execute_reply.started":"2023-03-19T03:13:24.271420Z","shell.execute_reply":"2023-03-19T03:13:24.295565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essay_collection['topics'] = topics\nessay_topic_map = {i: essay_collection.loc[i, 'topics'] for i in essay_collection.index}\ndata['topics'] = data['essay_id'].map(essay_topic_map)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.301235Z","iopub.execute_input":"2023-03-19T03:13:24.303453Z","iopub.status.idle":"2023-03-19T03:13:24.377479Z","shell.execute_reply.started":"2023-03-19T03:13:24.303416Z","shell.execute_reply":"2023-03-19T03:13:24.376579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.382155Z","iopub.execute_input":"2023-03-19T03:13:24.382915Z","iopub.status.idle":"2023-03-19T03:13:24.397699Z","shell.execute_reply.started":"2023-03-19T03:13:24.382878Z","shell.execute_reply":"2023-03-19T03:13:24.396722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('/kaggle/working/topic_mapping.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.399518Z","iopub.execute_input":"2023-03-19T03:13:24.400319Z","iopub.status.idle":"2023-03-19T03:13:24.783031Z","shell.execute_reply.started":"2023-03-19T03:13:24.400282Z","shell.execute_reply":"2023-03-19T03:13:24.781888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# claim_evidence_data = data.loc[data['discourse_type'].isin(['Claim', 'Evidence'])].reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.784823Z","iopub.execute_input":"2023-03-19T03:13:24.785271Z","iopub.status.idle":"2023-03-19T03:13:24.790648Z","shell.execute_reply.started":"2023-03-19T03:13:24.785226Z","shell.execute_reply":"2023-03-19T03:13:24.789315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# claim_evidence_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.792729Z","iopub.execute_input":"2023-03-19T03:13:24.793642Z","iopub.status.idle":"2023-03-19T03:13:24.803205Z","shell.execute_reply.started":"2023-03-19T03:13:24.793602Z","shell.execute_reply":"2023-03-19T03:13:24.802040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:24.804942Z","iopub.execute_input":"2023-03-19T03:13:24.805365Z","iopub.status.idle":"2023-03-19T03:13:25.123800Z","shell.execute_reply.started":"2023-03-19T03:13:24.805325Z","shell.execute_reply":"2023-03-19T03:13:25.122749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = sentence_embedding_model.encode(list(data.loc[data['discourse_effectiveness'] == \"Effective\"].discourse_text))\ne_indices = data.loc[data['discourse_effectiveness'] == \"Effective\"].index.values\nprint(e_indices[0])\ne_topics = data.loc[e_indices, 'topics'].values\n","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:25.125440Z","iopub.execute_input":"2023-03-19T03:13:25.125872Z","iopub.status.idle":"2023-03-19T03:13:32.536560Z","shell.execute_reply.started":"2023-03-19T03:13:25.125787Z","shell.execute_reply":"2023-03-19T03:13:32.535340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e_topics","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:32.538263Z","iopub.execute_input":"2023-03-19T03:13:32.538685Z","iopub.status.idle":"2023-03-19T03:13:32.546095Z","shell.execute_reply.started":"2023-03-19T03:13:32.538642Z","shell.execute_reply":"2023-03-19T03:13:32.544962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_index_mapping = {i : [] for i in range(0,15)}\nfor row in range(len(e_topics)):\n    topic_index_mapping[e_topics[row]].append(e_indices[row])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:32.547724Z","iopub.execute_input":"2023-03-19T03:13:32.548393Z","iopub.status.idle":"2023-03-19T03:13:32.565599Z","shell.execute_reply.started":"2023-03-19T03:13:32.548355Z","shell.execute_reply":"2023-03-19T03:13:32.564623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_best_effective_example(query_indices, effective_indices, similarity_matrix, topic_index_mapping, context = False):\n    # print(query, discourse_type)\n    # We are assuming that the query is either ineffective or adequate\n    queries = data.loc[query_indices, :]\n    query_topics, _ = topic_model.transform(queries['discourse_text'].values)\n    better_examples = []\n    print(\"Mapped Query Topics\")\n    for idx in range(len(queries)):\n        topic = query_topics[idx]\n        print(\"\\nQuery:\", queries.values[idx][2])\n        discourse_element = queries.loc[queries.index.values[idx], 'discourse_type']\n        # print(discourse_element)\n        \"\"\"1. Extract the indices for that topic - only effective ones are shown\"\"\"\n        related_indices = topic_index_mapping[topic]\n    \n        \"\"\"2. Extract those values from the dataframe which have the same discourse type\"\"\"\n        same_element = data.loc[related_indices, :][data['discourse_type'] == discourse_element]\n        # print(same_element)\n        similarity_score = similarity_matrix[idx, torch.argmax(similarity_matrix[idx])]\n        # print(similarity_score)\n        example = data.loc[effective_indices[torch.argmax(similarity_matrix[idx])], 'discourse_text']\n        # print(effective_indices[torch.argmax(similarity_matrix[idx])])\n        better_examples.append(example)\n        if context:\n            print(\"Query context:\", queries.loc[queries.index.values[idx], 'context'])\n            print(\"Matching context:\", data.loc[effective_indices[torch.argmax(similarity_matrix[idx])], 'context'])\n        print(\"Better example:\", example)\n    return better_examples\n        \n    \n\n    \n    \n        \n        \n        \n    \n    \"\"\"\n        \n    topic_related_data = data.loc[data['topics'] == query_topic[0]][data['discourse_type'] == discourse_type][data['discourse_effectiveness'] == 'Effective']\n    rows = topic_related_data.index\n    print(\"Row count\", len(rows))\n    encoded_query = sentence_embedding_model.encode(query)\n    similarities = util.cos_sim(encoded_query, embeddings[rows])\n    # print(len(rows) == len(similarities[0]))\n    new_data = pd.DataFrame(data, columns = data.columns)\n    # print(similarities)\n    new_data.loc[rows, 'sim_scores'] = list(similarities[0])\n    return new_data.sort_values(by = 'sim_scores', ascending = False).head(1)['discourse_text'].values\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:45:42.728245Z","iopub.execute_input":"2023-03-19T03:45:42.729369Z","iopub.status.idle":"2023-03-19T03:45:42.739936Z","shell.execute_reply.started":"2023-03-19T03:45:42.729308Z","shell.execute_reply":"2023-03-19T03:45:42.738588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = data.loc[data['discourse_effectiveness'] != \"Effective\"]\nq_indices = test_set.index\ntest_set.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:32.580482Z","iopub.execute_input":"2023-03-19T03:13:32.580866Z","iopub.status.idle":"2023-03-19T03:13:32.602545Z","shell.execute_reply.started":"2023-03-19T03:13:32.580829Z","shell.execute_reply":"2023-03-19T03:13:32.601582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_embeddings = sentence_embedding_model.encode(list(test_set['discourse_text']))","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:32.604128Z","iopub.execute_input":"2023-03-19T03:13:32.604514Z","iopub.status.idle":"2023-03-19T03:13:47.019728Z","shell.execute_reply.started":"2023-03-19T03:13:32.604473Z","shell.execute_reply":"2023-03-19T03:13:47.018542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:47.021470Z","iopub.execute_input":"2023-03-19T03:13:47.022427Z","iopub.status.idle":"2023-03-19T03:13:47.029507Z","shell.execute_reply.started":"2023-03-19T03:13:47.022393Z","shell.execute_reply":"2023-03-19T03:13:47.028343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_matrix = util.cos_sim(query_embeddings, embeddings)  #query embeddings vs effective embeddings","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:13:47.031234Z","iopub.execute_input":"2023-03-19T03:13:47.032007Z","iopub.status.idle":"2023-03-19T03:13:49.196663Z","shell.execute_reply.started":"2023-03-19T03:13:47.031965Z","shell.execute_reply":"2023-03-19T03:13:49.195586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set['predictions'] = find_best_effective_example(q_indices, e_indices, similarity_matrix, topic_index_mapping)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-03-18T23:09:09.629783Z","iopub.execute_input":"2023-03-18T23:09:09.630483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data['predictions'] = data.apply(lambda x : find_best_effective_example(x['discourse_text'], x['discourse_type']), axis = 1)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set.to_csv('/kaggle/working/dataset_with_best_example_and_topic.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#test_data  = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find_best_effective_example(test_data.loc[3, 'discourse_text'], test_data.loc[3, 'discourse_type'])\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_set = data.loc[data['discourse_effectiveness'] != 'Effective'].sample(1000)\n#embeddings ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_set['predictions'] = test_set.apply(lambda x : find_best_effective_example(x['discourse_text'], x['discourse_type']), axis = 1)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:15:44.263939Z","iopub.execute_input":"2023-03-19T03:15:44.264967Z","iopub.status.idle":"2023-03-19T03:15:44.699204Z","shell.execute_reply.started":"2023-03-19T03:15:44.264926Z","shell.execute_reply":"2023-03-19T03:15:44.697912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from pathlib import Path  \nfilepath = Path('/kaggle/working/test_predictions.csv')  \nfilepath.parent.mkdir(parents=True, exist_ok=True)  \ntest_set.to_csv(filepath) \"\"\" ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What if we take the essays with the most similar context and then output the corresponding discourse element as an example?\n","metadata":{}},{"cell_type":"code","source":"random_id = data['essay_id'].sample(1).values[0]\nprint(random_id)\nnew_data = data.loc[data['essay_id'] == random_id]\nfor index, row in new_data.iterrows():\n    print(\"X \", row[\"discourse_text\"],\" \",row[\"discourse_type\"], \" \", row[\"discourse_effectiveness\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:15:48.200220Z","iopub.execute_input":"2023-03-19T03:15:48.200849Z","iopub.status.idle":"2023-03-19T03:15:48.225700Z","shell.execute_reply.started":"2023-03-19T03:15:48.200785Z","shell.execute_reply":"2023-03-19T03:15:48.224395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-19T01:32:46.003965Z","iopub.execute_input":"2023-03-19T01:32:46.004611Z","iopub.status.idle":"2023-03-19T01:32:46.033638Z","shell.execute_reply.started":"2023-03-19T01:32:46.004573Z","shell.execute_reply":"2023-03-19T01:32:46.032598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_context(row, dataset):\n    discourse_element = row['discourse_type']\n    # print(\"Current discourse element:\", discourse_element)\n    essay_id = row['essay_id']\n    # print(\"Current essay ID:\", essay_id)\n    essay = dataset.loc[dataset[\"essay_id\"] == essay_id]\n    # print(row)\n    if discourse_element in [\"Lead\", \"Position\", \"Counterclaim\"]:\n        # return row[\"discourse_text\"]\n        # print(\"One of lead, position, counterclaim. No change.\")\n        return [row['discourse_text']]\n    elif discourse_element in [\"Claim\"]:\n        context = essay[essay[\"discourse_type\"].isin([\"Lead\", \"Position\"])]\n        evidence_found = 0\n        for _, rrow in essay.iloc[row.name::1].iterrows():\n            if rrow[\"discourse_type\"] == \"Evidence\":\n                # print(\"Adding evidence to context\")\n                evidence_found = 1\n                context = context.append(rrow)\n            elif not evidence_found:\n                continue\n            else:\n                break\n        # return context.groupby(['essay_id'])['discourse_text'].transform(lambda x: ' '.join(x))\n        context.drop_duplicates(inplace = True, keep = \"first\")\n    \n    elif discourse_element == \"Evidence\":\n        context = essay[essay[\"discourse_type\"].isin([\"Lead\", \"Position\"])]\n        evidence_found = None\n        for index, rrow in essay.sort_index(ascending = False).iloc[row.name::-1].iterrows():\n            if rrow[\"discourse_type\"] == \"Claim\":\n                # print(\"Claim found for this evidence\")\n                evidence_found = \"Claim\"\n                context = context.append(rrow)\n                break\n            elif rrow[\"discourse_type\"] == \"Rebuttal\":\n                # print(\"Rebuttal found for this evidence\")\n                evidence_found = \"Rebuttal\"\n                context = context.append(rrow)\n                continue\n            elif rrow[\"discourse_type\"] == \"Counterclaim\":\n                # print(\"Counterclaim found for this evidence\")\n                evidence_found = \"Counterclaim\"\n                context = context.append(rrow)\n                break\n            else:\n                continue\n        context.drop_duplicates(inplace = True, keep = \"first\")\n    \n    elif discourse_element == \"Rebuttal\":\n        context = essay[essay[\"discourse_type\"].isin([\"Lead\", \"Position\"])]\n        evidence_found = 0\n        for _, rrow in dataset[row.name::1].iterrows():\n            if rrow[\"discourse_type\"] == \"Evidence\":\n                evidence_found = 1\n                # print(rrow[\"discourse_text\"])\n                context = context.append(rrow)\n            elif not evidence_found:\n                continue\n            else:\n                break\n        for _, rrow in dataset.iloc[row.name::-1].iterrows():\n            # print(rrow[\"discourse_text\"])\n            if rrow[\"discourse_type\"] == \"Counterclaim\":\n                evidence_found = \"Counterclaim\"\n                # print(\"TADA\")\n                context = context.append(rrow)\n                # print(context.values)\n                break\n            else:\n                continue\n        context.drop_duplicates(inplace = True, keep = \"first\")\n        \n        \n    elif discourse_element == 'Concluding Statement':\n        context = essay[essay[\"discourse_type\"] != discourse_element]\n        context.drop_duplicates(inplace = True, keep = \"first\")\n    return context['discourse_text']\n        \n                \n            \n        \n        \n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:25:21.061208Z","iopub.execute_input":"2023-03-19T03:25:21.061646Z","iopub.status.idle":"2023-03-19T03:25:21.079650Z","shell.execute_reply.started":"2023-03-19T03:25:21.061604Z","shell.execute_reply":"2023-03-19T03:25:21.078433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_context(data.iloc[5, :], data).values","metadata":{"execution":{"iopub.status.busy":"2023-03-19T01:37:01.864935Z","iopub.execute_input":"2023-03-19T01:37:01.865538Z","iopub.status.idle":"2023-03-19T01:37:01.890211Z","shell.execute_reply.started":"2023-03-19T01:37:01.865500Z","shell.execute_reply":"2023-03-19T01:37:01.889271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in data.iterrows():\n    context_text = \"\"\n    try:\n        retrieved_context = get_context(row, data).values\n    except:\n        retrieved_context = get_context(row, data)\n    # print(retrieved_context)\n    context_text = ' '.join(retrieved_context)\n    data.loc[index, 'context'] = context_text\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:28:44.184728Z","iopub.execute_input":"2023-03-19T03:28:44.185452Z","iopub.status.idle":"2023-03-19T03:33:06.207038Z","shell.execute_reply.started":"2023-03-19T03:28:44.185413Z","shell.execute_reply":"2023-03-19T03:33:06.205952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('full_context.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:33:06.209273Z","iopub.execute_input":"2023-03-19T03:33:06.209683Z","iopub.status.idle":"2023-03-19T03:33:06.673626Z","shell.execute_reply.started":"2023-03-19T03:33:06.209639Z","shell.execute_reply":"2023-03-19T03:33:06.672584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"effective_context_embeddings = sentence_embedding_model.encode(list(data.loc[e_indices, 'context']))\nquery_context_embeddings = sentence_embedding_model.encode(list(data.loc[q_indices, 'context']))\ncontext_matrix = util.cos_sim(query_context_embeddings, effective_context_embeddings)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:33:06.675068Z","iopub.execute_input":"2023-03-19T03:33:06.677960Z","iopub.status.idle":"2023-03-19T03:33:40.884774Z","shell.execute_reply.started":"2023-03-19T03:33:06.677916Z","shell.execute_reply":"2023-03-19T03:33:40.883654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting the elements with the most similar context","metadata":{}},{"cell_type":"code","source":"test_set['context_predictions'] = find_best_effective_example(q_indices, e_indices, context_matrix, topic_index_mapping, context = True)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T03:45:50.474864Z","iopub.execute_input":"2023-03-19T03:45:50.475400Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set.to_csv('context_examples.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmenting the matrix to focus on the combination of contextual similarity and prompt similarity\n","metadata":{}},{"cell_type":"code","source":"augmented_sim_matrix = torch.mul(similarity_matrix, context_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set['augmented_predictions'] = find_best_effective_example(q_indices, e_indices, augmented_sim_matrix, topic_index_mapping, context = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set.to_csv('augmented_predictions_all.csv')","metadata":{},"execution_count":null,"outputs":[]}]}